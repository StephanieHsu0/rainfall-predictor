{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8vm35IKjzPD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import os\n",
        "import re\n",
        "\n",
        "# --- 1. 解壓縮資料\n",
        "zip_path = '/content/data.zip'\n",
        "extract_path = '/content/data/raw/'\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f\"資料已解壓縮到：{extract_path}\")\n",
        "\n",
        "# --- 2. 開始批次清洗\n",
        "raw_folder = os.path.join(extract_path, 'data', 'raw')  # 注意這邊又多了一層 data/raw/\n",
        "cleaned_base_folder = '/content/data/cleaned/'\n",
        "os.makedirs(cleaned_base_folder, exist_ok=True)\n",
        "\n",
        "# 保留欄位\n",
        "keep_columns = ['ObsTime', 'StnPres', 'Temperature', 'RH', 'WS', 'Precp']\n",
        "\n",
        "# 遍歷所有測站\n",
        "for station_id in os.listdir(raw_folder):\n",
        "    station_path = os.path.join(raw_folder, station_id)\n",
        "    if not os.path.isdir(station_path):\n",
        "        continue\n",
        "\n",
        "    for year_folder in os.listdir(station_path):\n",
        "        year_path = os.path.join(station_path, year_folder)\n",
        "        if not os.path.isdir(year_path):\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n正在處理站點 {station_id} 年 {year_folder}\")\n",
        "\n",
        "        cleaned_folder = os.path.join(cleaned_base_folder, station_id, year_folder.split('_')[1])\n",
        "        os.makedirs(cleaned_folder, exist_ok=True)\n",
        "\n",
        "        for file_name in sorted(os.listdir(year_path)):\n",
        "            if not file_name.endswith('.csv'):\n",
        "                continue\n",
        "\n",
        "            file_path = os.path.join(year_path, file_name)\n",
        "            print(f\"\\n正在處理：{file_path}\")\n",
        "\n",
        "            try:\n",
        "                # 嘗試讀取\n",
        "                df = pd.read_csv(file_path, encoding='utf-8', skiprows=1)\n",
        "                print(f\"{file_name} (utf-8) 成功讀取\")\n",
        "            except Exception as e1:\n",
        "                try:\n",
        "                    df = pd.read_csv(file_path, encoding='big5', skiprows=1)\n",
        "                    print(f\"{file_name} (big5) 成功讀取\")\n",
        "                except Exception as e2:\n",
        "                    print(f\"{file_name} 讀取失敗！錯誤訊息：{e2}\")\n",
        "                    continue\n",
        "\n",
        "            # 印出欄位名和前3筆資料\n",
        "            print(f\"欄位名稱：{list(df.columns)}\")\n",
        "            print(df.head(3))\n",
        "\n",
        "            # =============== 清洗流程 ===============\n",
        "            try:\n",
        "                df = df[keep_columns]\n",
        "\n",
        "                df['Precp'] = df['Precp'].replace('T', 0)\n",
        "                df.replace('--', np.nan, inplace=True)\n",
        "\n",
        "                for col in keep_columns[1:]:  # ObsTime不用轉\n",
        "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "                df.fillna(method='ffill', inplace=True)\n",
        "                df.fillna(method='bfill', inplace=True)\n",
        "\n",
        "                # 從檔名提取日期\n",
        "                date_match = re.search(r'(\\d{4}-\\d{2}-\\d{2})', file_name)\n",
        "                if date_match:\n",
        "                    date_str = date_match.group(1)\n",
        "                    base_date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
        "                else:\n",
        "                    print(f\"無法解析日期：{file_name}\")\n",
        "                    continue\n",
        "\n",
        "                df['time'] = df['ObsTime'].apply(lambda x: base_date + pd.to_timedelta(int(x), unit='h'))\n",
        "                df = df.sort_values('time').reset_index(drop=True)\n",
        "\n",
        "                # 累積雨量\n",
        "                df['Precp_3h'] = df['Precp'].rolling(window=3, min_periods=1).sum()\n",
        "                df['Precp_6h'] = df['Precp'].rolling(window=6, min_periods=1).sum()\n",
        "\n",
        "                # 整理欄位\n",
        "                df_final = df[['time', 'StnPres', 'Temperature', 'RH', 'WS', 'Precp', 'Precp_3h', 'Precp_6h']]\n",
        "\n",
        "                # 儲存\n",
        "                cleaned_file_path = os.path.join(cleaned_folder, file_name.replace('.csv', '_cleaned.csv'))\n",
        "                df_final.to_csv(cleaned_file_path, index=False, encoding='utf-8-sig')\n",
        "\n",
        "                print(f\"{file_name} 清理成功並儲存！\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"{file_name} 清理失敗！錯誤：{e}\")\n",
        "\n",
        "print(\"\\n整個多站點多年資料清洗完成！\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.make_archive('/content/cleaned_data', 'zip', '/content/data/cleaned')\n",
        "\n",
        "from google.colab import files\n",
        "files.download('/content/cleaned_data.zip')\n"
      ],
      "metadata": {
        "id": "baNaLKAmkAaS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}